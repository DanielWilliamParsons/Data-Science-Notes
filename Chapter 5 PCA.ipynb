{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principle Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Algorithm\n",
    "Be able to explain this for the exam:\n",
    "Some data is often redundant due to the correlations between variables. So, we want to reduce this redundancy. We essentially want to reduce our data from high dimensionality to low dimensionality. We might also want to extract features for a machine learning algorithm, or be able to visualize the data more reliably.\n",
    "\n",
    "**1 Standardize the data**\n",
    "Calculate the mean of each variable and subtract this mean from all the data records in the associated variable. Should probably also divide by the standard deviation.\n",
    "\n",
    "**2 Calculate the covariance matrix**\n",
    "Measure the relationships between pairs of variables, determine the variance and covariance between variables.\n",
    "\n",
    "**3 Calculate the eigenvalues and eigenvectors of the covariance matrix**\n",
    "Eigenvectors represent the direction of maximum variance (what linear combination of original covariance variables gives max variance) in the data while eigenvalues represent the amount of variance explained by each eigenvector.\n",
    "\n",
    "**4 Sort the eigenvalues from the largest to the smallest**\n",
    "The eigenvector that corresponds to the highest eigenvalue is determined as the first principal component of the dataset.\n",
    "\n",
    "**5 Reduce the dimensionality**\n",
    "The Principal Components with less significance are ignored.\n",
    "\n",
    "**6 Transform and reconstruct the dataset**\n",
    "The transformed data can be reconstructed into the original feature space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    X1   X2\n",
      "0  2.5  2.4\n",
      "1  0.5  0.7\n",
      "2  2.2  2.9\n",
      "3  1.9  2.2\n",
      "4  3.1  3.0\n",
      "5  2.3  2.7\n",
      "6  2.0  1.6\n",
      "7  1.0  1.1\n",
      "8  1.5  1.6\n",
      "9  1.1  0.9\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    {\"X1\": 2.5, \"X2\": 2.4},\n",
    "    {\"X1\": 0.5, \"X2\": 0.7},\n",
    "    {\"X1\": 2.2, \"X2\": 2.9},\n",
    "    {\"X1\": 1.9, \"X2\": 2.2},\n",
    "    {\"X1\": 3.1, \"X2\": 3},\n",
    "    {\"X1\": 2.3, \"X2\": 2.7},\n",
    "    {\"X1\": 2, \"X2\": 1.6},\n",
    "    {\"X1\": 1, \"X2\": 1.1},\n",
    "    {\"X1\": 1.5, \"X2\": 1.6},\n",
    "    {\"X1\": 1.1, \"X2\": 0.9},\n",
    "]\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1JUlEQVR4nO3df1SUdd7/8deAwVDCGBUyJilpYYS/kwLLX6lo3hS5u5mt6VrtGrda5n0qveuIP3aXylp3a00r76I7t/xRqWmJmvhjU1tSZBMptx+klqCVNSAJtszn+4df5m4CFBCYmYvn45zrnOZzfa6Z93ycmNe5Ptf1GZsxxggAAMAignxdAAAAQFMi3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3ADwiS+++EI2m01ZWVm+LsVLdna2evXqJbvdLpvNpu+//97XJQFoIMIN0MT27dunX/7yl+rUqZPsdrsuvfRSDRs2TM8880yzvearr76qP//5zzXajxw5otmzZys/P7/ZXvvntm7dKpvN5tnOO+88XX755Ro/frw+//zzJnmNnTt3avbs2U0ePL799lvddtttCgsL08KFC/XKK6/oggsuqLXvuHHjZLfb9a9//avGvscee0w2m03r1q3ztC1fvlzjxo3TFVdcIZvNpkGDBjVp7efi0Ucflc1m09atW2vsW7ZsmWw2m/76179Kkn744QctXLhQw4cPl9PpVHh4uHr37q1FixapqqqqhSsH6mAANJkdO3aYkJAQ07VrVzNv3jzzwgsvmFmzZpnhw4ebLl26NNvrjho1ynTq1KlG+wcffGAkmZdeeqnZXvvntmzZYiSZ++67z7zyyivmxRdfNFOmTDEhISEmMjLSfPXVV8YYY4qKihpd2/z5840kU1RU1KS1r1+/3kgymzZtOmvfo0ePmgsvvNAMHjzYq/3zzz83YWFh5he/+IVX+8CBA03btm3N4MGDzYUXXmgGDhzYlKWfk5MnT5ouXbqYuLg4U1lZ6Wn/7rvvTHR0tOnXr5+pqqoyxhizb98+Y7PZzNChQ80TTzxhFi9ebG699VYjyYwfP95XbwHwQrgBmtBNN91kLrnkEvPdd9/V2Hf06NFme92WDjcnTpyoc191uFm5cqVX+9NPP20kmT/+8Y/GGP8MNy+//LKRZD744IN69X/++eeNJJOVleVpGzFihImIiDBffvmlV99Dhw55AsLVV1/tV+HGGGM2btxoJJnZs2d72iZNmmSCg4PN3r17PW1ff/21KSgoqHH8xIkTjSTzySeftES5wBkRboAmFBcXZwYNGlTv/q+88orp16+fCQsLM+3atTM33HCD2bBhg2f/6tWrzU033WScTqcJCQkxl19+uZk7d67597//7ekzcOBAI8lr69Spkydk/Hz7aZh4//33TUpKiomIiDBhYWFmwIAB5r333vOqMSMjw0gy+/fvN2PHjjXt2rUzvXr1qvM91RVuCgoKjCTz29/+1hhTd7jZvHmzuf766835559vHA6Hufnmm01hYWGNen6+nS3orFixwvTp08fY7XZz0UUXmV//+tdeAaS2cZwwYcIZn9Ptdpv+/fubiy++2HzzzTfmtddeM5LM008/fcbjGhJuSkpKTHBwsFfoqPbxxx8bSeaZZ54xxhhz6tQpM3v2bNO1a1cTGhpqIiMjTf/+/c3GjRvr9Vp33HGHCQ0NNQcOHDA7d+40NpvNTJ8+vV7HvvXWW0aSeeutt+rVH2hObZpvwgtofTp16qRdu3apoKBACQkJZ+w7Z84czZ49W8nJyZo7d65CQkL0j3/8Qzk5ORo+fLgkKSsrS23bttX06dPVtm1b5eTkaNasWSotLdX8+fMlSY888ohcLpe+/PJLLViwQJLUtm1bXXXVVZo7d65mzZql3/3ud7rhhhskScnJyZKknJwcjRw5Un379lVGRoaCgoL00ksvaciQIfr73/+uxMREr3p/9atf6YorrtAf//hHGWMaPDafffaZJOmiiy6qs8+7776rkSNH6vLLL9fs2bN18uRJPfPMM+rfv7/y8vLUuXNnjR49Wv/617/02muvacGCBbr44oslSZdcckmdz5uVlaWJEyeqX79+yszM1NGjR/WXv/xFO3bs0N69e9WuXTs98sgjiouL0/PPP6+5c+cqNjZWXbp0OeN7stlseu6559S7d2+lp6fr73//u6655hpNnjy5weNTl/bt22vgwIFasWKFMjIyvPYtX75cwcHB+tWvfiVJmj17tjIzM3XPPfcoMTFRpaWl2r17t/Ly8jRs2LCzvtaf/vQnrV+/XpMmTdK3336rjh07as6cOfWqs6SkRJI8/x6AT/k6XQFWsnHjRhMcHGyCg4NNUlKSeeihh8yGDRvMqVOnvPp98sknJigoyNx6662eqYpqbrfb898//PBDjdeYNGmSOf/8801FRYWnraHTUm6321xxxRUmJSWlxuvFxsaaYcOGedqqz5SMHTu2XmNQfebmxRdfNF9//bU5cuSIefvtt03nzp2NzWbzTPnUduamV69eJioqynz77beetn/+858mKCjI63qOhkxLnTp1ykRFRZmEhARz8uRJT/u6deuMJDNr1ixP20svvdSgaalqM2fONJJMcHCw2bNnz1n7N3Ra6rnnnjOSzL59+7za4+PjzZAhQzyPe/bsaUaNGlXv5z3Ta0kyq1evrtcxlZWVJj4+3sTGxpoff/zxnF4faArcLQU0oWHDhmnXrl26+eab9c9//lNPPPGEUlJSdOmll+qtt97y9Fu9erXcbrdmzZqloCDv/w1tNpvnv8PCwjz/XVZWpm+++UY33HCDfvjhB3388ceNrjM/P1+ffPKJ7rjjDn377bf65ptv9M0336i8vFw33nijtm/fLrfb7XXMvffe26DXuOuuu3TJJZeoQ4cOGjVqlMrLy/Xyyy/rmmuuqbV/cXGx8vPz9Zvf/EaRkZGe9h49emjYsGF65513Gv5GJe3evVvHjh3Tf/7nf8put3vaR40apW7duuntt99u1PP+VPXZig4dOpz1jF1jjB49Wm3atNHy5cs9bQUFBSosLNSYMWM8be3atdP+/fv1ySefNPq1qt/L+eefr+uvv75ex0yZMkWFhYX661//qjZtmBCA7xFugCbWr18/vfnmm/ruu++Um5urmTNnqqysTL/85S9VWFgo6fQUTVBQkOLj48/4XPv379ett94qh8OhiIgIXXLJJRo3bpwkyeVyNbrG6i+/CRMm6JJLLvHalixZosrKyhrPHxsb26DXmDVrljZt2qScnBx9+OGHOnLkiO688846+x88eFCSFBcXV2PfVVdd5QlfDXWm5+3WrZtnf2MdPnxYGRkZSkhI0OHDh/XEE0+c0/PV5uKLL9aNN96oFStWeNqWL1+uNm3aaPTo0Z62uXPn6vvvv9eVV16p7t2768EHH9SHH35Y79cpKyvTfffdp7i4OJ06dUoPP/zwWY+ZP3++XnjhBc2bN0833XRTw94Y0EyI2EAzCQkJUb9+/dSvXz9deeWVmjhxolauXFnjuom6fP/99xo4cKAiIiI0d+5cdenSRXa7XXl5eXr44YdrnFlpiOpj58+fr169etXap23btl6Pf3oWqT66d++uoUOHNqq+QDJlyhRJ0vr16zV9+nT94Q9/0B133KHLL7+8SV/n9ttv18SJE5Wfn69evXppxYoVuvHGG72ucRkwYIA+++wzrVmzRhs3btSSJUu0YMECLV68WPfcc89ZX+ORRx5RSUmJcnNztWzZMj355JOaOHGi+vfvX2v/rKwsPfzww7r33nv16KOPNtl7Bc4V4QZoAdVTMcXFxZKkLl26yO12q7CwsM5wsXXrVn377bd68803NWDAAE97UVFRjb4/ncqqT3v1hbIRERF+E0A6deokSTpw4ECNfR9//LEuvvhiz4J6db2vsz3vkCFDvPYdOHDAs78xVq1apbfeeksLFixQx44d9ec//1kbNmzQ5MmTtX79+kY/b23S0tI0adIkz9TUv/71L82cObNGv8jISE2cOFETJ07UiRMnNGDAAM2ePfus4Wb37t1auHChpk6dqj59+iguLk7Lly/Xvffeq71799aYblqzZo3uuecejR49WgsXLmy6Nwo0AaalgCa0ZcuWWu8kqr5epHpqJC0tTUFBQZo7d26NMzDVxwcHB3s9lqRTp07p2WefrfH8F1xwQa3TVNVh4Ocr+fbt21ddunTRk08+qRMnTtQ47uuvv67zPTYXp9OpXr166eWXX/aqt6CgQBs3bvSa8qjrfdXmmmuuUVRUlBYvXqzKykpP+/r16/XRRx9p1KhRjaq3egqnd+/emjp1qqTT19zMmzdP2dnZWrlyZaOety7t2rVTSkqKVqxYoWXLlikkJERpaWlefb799luvx23btlXXrl293ndtqqqqNGnSJDmdTs2bN0/S6TF+5plnVFBQ4LkLr9r27dt1++23a8CAAfrb3/5W47oxwNc4cwM0oalTp+qHH37Qrbfeqm7duunUqVPauXOnli9frs6dO2vixImSpK5du+qRRx7RvHnzdMMNN2j06NEKDQ3VBx98oA4dOigzM1PJycm68MILNWHCBN13332y2Wx65ZVXag1Pffv21fLlyzV9+nT169dPbdu2VWpqqrp06aJ27dpp8eLFCg8P1wUXXKBrr71WsbGxWrJkiUaOHKmrr75aEydO1KWXXqqvvvpKW7ZsUUREhNauXdvSw6f58+dr5MiRSkpK0t133+25FdzhcGj27Nle71c6PY1y++2367zzzlNqamqtP5Vw3nnn6fHHH9fEiRM1cOBAjR071nMreOfOnfXAAw80qtZHH31UR44c0ZtvvukJopI0efJkvfzyy5o2bZpGjBih8PBwSacDwfbt2yWdDo/l5eX6/e9/L+n0dNJPz87VZcyYMRo3bpyeffZZpaSkqF27dl774+PjNWjQIPXt21eRkZHavXu3Xn/9dc/UWV2efvpp5eXl6Y033vDUK0k333yzbr75Zs2ZM0djxozRZZddpoMHD+rmm2+WzWbTL3/5yxohrkePHurRo8dZ3wvQrHx7sxZgLevXrzd33XWX6datm2nbtq3npximTp1a6wrFL774oundu7cJDQ31LMn/06X/d+zYYa677joTFhZmOnTo4Lm1XJLZsmWLp9+JEyfMHXfcYdq1a+dZxK/amjVrTHx8vGnTpk2NW6/37t1rRo8ebS666CITGhpqOnXqZG677TazefNmT5/qW8G//vrreo1BXYv4/Vxdi/i9++67pn///iYsLMxERESY1NRUr0X8qs2bN89ceumlJigoqF63hS9fvtwz1pGRkTUW8TOm/reC79692wQHB5spU6bUuj83N9cEBQWZ++67z9NW1+KDkkxGRsYZX69aaWmpCQsLM5LM0qVLa+z//e9/bxITE027du1MWFiY6datm/nDH/5QYymCnzp8+LBp27at+Y//+I9a9x88eNBccMEF5uabbzbGmDoXh2zoewGak82YRqzGBQAA4KeYKAUAAJZCuAEAAJZCuAEAAJZCuAEAAJZCuAEAAJZCuAEAAJbS6hbxc7vdOnLkiMLDwxu0hDsAAPAdY4zKysrUoUOHs66K3erCzZEjRxQTE+PrMgAAQCMcPnxYHTt2PGOfVhduqpcWP3z4sCIiInxcDQAAqI/S0lLFxMR4/URIXVpduKmeioqIiCDcAAAQYOpzSQkXFAMAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEtpdSsUAwCA5lHlNsotOq5jZRWKCrcrMTZSwUEt/yPVPj1zs2jRIvXo0cPzUwhJSUlav379GY9ZuXKlunXrJrvdru7du+udd95poWoBAEBdsguKdf3jORr7wvu6f1m+xr7wvq5/PEfZBcUtXotPw03Hjh312GOPac+ePdq9e7eGDBmiW265Rfv376+1/86dOzV27Fjdfffd2rt3r9LS0pSWlqaCgoIWrhwAAFTLLihW+tI8FbsqvNpLXBVKX5rX4gHHZowxLfqKZxEZGan58+fr7rvvrrFvzJgxKi8v17p16zxt1113nXr16qXFixfX6/lLS0vlcDjkcrn44UwAAM5Rldvo+sdzagSbajZJ0Q673nt4yDlNUTXk+9tvLiiuqqrSsmXLVF5erqSkpFr77Nq1S0OHDvVqS0lJ0a5du+p83srKSpWWlnptAACgaeQWHa8z2EiSkVTsqlBu0fEWq8nn4Wbfvn1q27atQkNDde+992rVqlWKj4+vtW9JSYnat2/v1da+fXuVlJTU+fyZmZlyOByeLSYmpknrBwCgNTtWVnewaUy/puDzcBMXF6f8/Hz94x//UHp6uiZMmKDCwsIme/6ZM2fK5XJ5tsOHDzfZcwMA0NpFhdubtF9T8Pmt4CEhIerataskqW/fvvrggw/0l7/8Rc8991yNvtHR0Tp69KhX29GjRxUdHV3n84eGhio0NLRpiwYAAJKkxNhIOR12lbgqVNtFvNXX3CTGRrZYTT4/c/NzbrdblZWVte5LSkrS5s2bvdo2bdpU5zU6AACgeQUH2ZSRevpykp9fLlz9OCM1vkXXu/FpuJk5c6a2b9+uL774Qvv27dPMmTO1detW/frXv5YkjR8/XjNnzvT0v//++5Wdna2nnnpKH3/8sWbPnq3du3drypQpvnoLAAC0eiMSnFo0ro+iHd5TT9EOuxaN66MRCc4Wrcen01LHjh3T+PHjVVxcLIfDoR49emjDhg0aNmyYJOnQoUMKCvq//JWcnKxXX31Vjz76qP77v/9bV1xxhVavXq2EhARfvQUAAKDTAWdYfLRfrFDsd+vcNDfWuQEAIPAE5Do3AAAATYFwAwAALIVwAwAALMXn69wAAJpPldv4xQWeQEsi3ACARWUXFGvO2kKv3/1xOuzKSI1v8VtzgZbEtBQAWFB2QbHSl+bV+EHDEleF0pfmKbug2EeVAc2PcAMAFlPlNpqztrDWpfCr2+asLVSVu1WtBIJWhHADABaTW3S8xhmbnzKSil0Vyi063nJFAS2IcAMAFnOsrO5g05h+QKAh3ACAxUSF28/eqQH9gEBDuAEAi0mMjZTTYa/xC83VbDp911RibGRLlgW0GMINAFhMcJBNGanxklQj4FQ/zkiNZ70bWBbhBgAsaESCU4vG9VG0w3vqKdph16JxfVjnBpbGIn4AYFEjEpwaFh/NCsVodQg3AGBhwUE2JXW5yNdlAC2KaSkAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGApbXxdAADAv1W5jXKLjutYWYWiwu1KjI1UcJDN12UBdSLcAADqlF1QrDlrC1XsqvC0OR12ZaTGa0SC04eVAXVjWgoAUKvsgmKlL83zCjaSVOKqUPrSPGUXFPuoMuDMCDcAgBqq3EZz1hbK1LKvum3O2kJVuWvrAfgW4QYAUENu0fEaZ2x+ykgqdlUot+h4yxUF1BPhBgBQw7GyuoNNY/oBLYlwAwCoISrc3qT9gJZEuAEA1JAYGymnw666bvi26fRdU4mxkS1ZFlAvhBsAQA3BQTZlpMZLUo2AU/04IzWe9W7glwg3AIBajUhwatG4Pop2eE89RTvsWjSuD+vcwG+xiB8AoE4jEpwaFh/NCsUIKIQbAMAZBQfZlNTlIl+XAdQb01IAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSfBpuMjMz1a9fP4WHhysqKkppaWk6cODAGY/JysqSzWbz2ux2ewtVDAAA/J1Pw822bds0efJkvf/++9q0aZN+/PFHDR8+XOXl5Wc8LiIiQsXFxZ7t4MGDLVQxAADwd218+eLZ2dlej7OyshQVFaU9e/ZowIABdR5ns9kUHR3d3OUBAIAA5FfX3LhcLklSZGTkGfudOHFCnTp1UkxMjG655Rbt37+/zr6VlZUqLS312gAAgHX5Tbhxu92aNm2a+vfvr4SEhDr7xcXF6cUXX9SaNWu0dOlSud1uJScn68svv6y1f2ZmphwOh2eLiYlprrcAAAD8gM0YY3xdhCSlp6dr/fr1eu+999SxY8d6H/fjjz/qqquu0tixYzVv3rwa+ysrK1VZWel5XFpaqpiYGLlcLkVERDRJ7QAAoHmVlpbK4XDU6/vbp9fcVJsyZYrWrVun7du3NyjYSNJ5552n3r1769NPP611f2hoqEJDQ5uiTAAAEAB8Oi1ljNGUKVO0atUq5eTkKDY2tsHPUVVVpX379snpdDZDhQAAIND49MzN5MmT9eqrr2rNmjUKDw9XSUmJJMnhcCgsLEySNH78eF166aXKzMyUJM2dO1fXXXedunbtqu+//17z58/XwYMHdc899/jsfQAAAP/h03CzaNEiSdKgQYO82l966SX95je/kSQdOnRIQUH/d4Lpu+++029/+1uVlJTowgsvVN++fbVz507Fx8e3VNkAAMCP+c0FxS2lIRckAQAA/9CQ72+/uRUcAACgKRBuAACApRBuAACApfjFOjcAANRHldsot+i4jpVVKCrcrsTYSAUH2XxdFvwM4QYAEBCyC4o1Z22hil0Vnjanw66M1HiNSGCtM/wfpqUAAH4vu6BY6UvzvIKNJJW4KpS+NE/ZBcU+qgz+iHADAPBrVW6jOWsLVdu6JdVtc9YWqsrdqlY2wRkQbgAAfi236HiNMzY/ZSQVuyqUW3S85YqCXyPcAAD82rGyuoNNY/rB+gg3AAC/FhVub9J+sD7CDQDAryXGRsrpsKuuG75tOn3XVGJsZEuWBT9GuAEA+LXgIJsyUk//OPLPA07144zUeNa7gQfhBgDg90YkOLVoXB9FO7ynnqIddi0a14d1buCFRfwAAAFhRIJTw+KjWaEYZ0W4AQAEjOAgm5K6XOTrMuDnmJYCAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACW0sbXBQCAP6lyG+UWHdexsgpFhduVGBup4CCbr8sC0ACEGwD4/7ILijVnbaGKXRWeNqfDrozUeI1IcPqwMgANwbQUAOh0sElfmucVbCSpxFWh9KV5yi4o9lFlABqKcAOg1atyG81ZWyhTy77qtjlrC1Xlrq0HAH9DuAHQ6uUWHa9xxuanjKRiV4Vyi463XFEAGo1wA6DVO1ZWd7BpTD8AvkW4AdDqRYXbm7QfAN8i3ABo9RJjI+V02FXXDd82nb5rKjE2siXLAtBIhBsArV5wkE0ZqfGSVCPgVD/OSI1nvRsgQBBuAEDSiASnFo3ro2iH99RTtMOuReP6sM4NEEBYxA8A/r8RCU4Ni49mhWIgwBFuAOAngoNsSupyka/LAHAOmJYCAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACW4tNwk5mZqX79+ik8PFxRUVFKS0vTgQMHznrcypUr1a1bN9ntdnXv3l3vvPNOC1QLAAACgU/DzbZt2zR58mS9//772rRpk3788UcNHz5c5eXldR6zc+dOjR07Vnfffbf27t2rtLQ0paWlqaCgoAUrBwAA/spmjDG+LqLa119/raioKG3btk0DBgyotc+YMWNUXl6udevWedquu+469erVS4sXLz7ra5SWlsrhcMjlcikiIqLJagcAAM2nId/ffnXNjcvlkiRFRkbW2WfXrl0aOnSoV1tKSop27dpVa//KykqVlpZ6bQAAwLr8Jty43W5NmzZN/fv3V0JCQp39SkpK1L59e6+29u3bq6SkpNb+mZmZcjgcni0mJqZJ6wYAAP7Fb8LN5MmTVVBQoGXLljXp886cOVMul8uzHT58uEmfHwAA+Jc2vi5AkqZMmaJ169Zp+/bt6tix4xn7RkdH6+jRo15tR48eVXR0dK39Q0NDFRoa2mS1AgAA/+bTMzfGGE2ZMkWrVq1STk6OYmNjz3pMUlKSNm/e7NW2adMmJSUlNVeZAAAggPj0zM3kyZP16quvas2aNQoPD/dcN+NwOBQWFiZJGj9+vC699FJlZmZKku6//34NHDhQTz31lEaNGqVly5Zp9+7dev755332PgAAgP/w6ZmbRYsWyeVyadCgQXI6nZ5t+fLlnj6HDh1ScXGx53FycrJeffVVPf/88+rZs6def/11rV69+owXIQMAgNbDr9a5aQmscwMAQOAJ2HVuAAAAzhXhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWEqDws2zzz6roUOH6rbbbqvx45XffPONLr/88iYtDgAAoKHqHW6efvppPfjgg+rWrZtCQ0N10003eX7MUpKqqqp08ODBZikSAACgvur9q+DPPfecXnjhBd1xxx2SpPT0dKWlpenkyZOaO3dusxUIAADQEPUON0VFRUpOTvY8Tk5OVk5OjoYOHaoff/xR06ZNa476AAAAGqTe4ebiiy/W4cOH1blzZ09bQkKCcnJyNGTIEB05cqQ56gMAAGiQel9zc/311+vNN9+s0R4fH6/Nmzdr/fr1TVoYAABAY9T7zM2MGTO0Z8+eWvddffXVysnJ0euvv95khQEAADRGvc/crFy5UnfeeWed+yMiIrRjx44mKQoAAKCx6h1uXn75ZSUmJqqgoKDGvueee04JCQlq06beJ4IAAACaRb3DTUFBgRISEnTNNdcoMzNTbrdbhw4d0tChQ/XQQw/pySef5LobAADgczZjjGnIAWvWrNGkSZMUHR2toqIiJSYmasmSJerUqVNz1dikSktL5XA45HK5FBER4etyAABAPTTk+7vBvy113XXXqXv37vrwww/ldrv16KOPBkywAQAA1tegcPPaa68pPj5ebrdbH330kdLT0zV8+HA98MADqqioaK4aAQAA6q3e4eYXv/iFfvvb32r27NnavHmz4uLi9MQTT2jLli1655131LNnT+3atas5awUAADiret/eVFJSor179+qKK67wak9OTlZ+fr5mzJihgQMH6tSpU01eJAAAQH3V+4Jit9utoKAzn+jZvn27BgwY0CSFNRcuKAYAIPA0ywXFZws2kvw+2AAAAOtr8N1SAAAA/oxwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALKWNrwsA4BtVbqPcouM6VlahqHC7EmMjFRxk83VZlsDYAr5FuAFaoeyCYs1ZW6hiV4WnzemwKyM1XiMSnD6sLPAxtoDvMS0FtDLZBcVKX5rn9eUrSSWuCqUvzVN2QbGPKgt8jC3gHwg3QCtS5Taas7ZQppZ91W1z1haqyl1bD5wJYwv4D8IN0IrkFh2vcVbhp4ykYleFcouOt1xRFsHYAv6DcAO0IsfK6v7ybUw//B/GFvAfhBugFYkKtzdpP/wfxhbwH4QboBVJjI2U02FXXTcl23T6zp7E2MiWLMsSGFvAfxBugFYkOMimjNR4SarxJVz9OCM1njVZGoGxBfwH4QZoZUYkOLVoXB9FO7ynR6Iddi0a14e1WM4BYwv4B5sxplXdl1haWiqHwyGXy6WIiAhflwP4DKvoNh/GFmh6Dfn+ZoVioJUKDrIpqctFvi7DkhhbwLeYlgIAAJZCuAEAAJZCuAEAAJZCuAEAAJbi03Czfft2paamqkOHDrLZbFq9evUZ+2/dulU2m63GVlJS0jIFAwAAv+fTcFNeXq6ePXtq4cKFDTruwIEDKi4u9mxRUVHNVCEAAAg0Pr0VfOTIkRo5cmSDj4uKilK7du2aviAAABDwAvKam169esnpdGrYsGHasWPHGftWVlaqtLTUawMAANYVUOHG6XRq8eLFeuONN/TGG28oJiZGgwYNUl5eXp3HZGZmyuFweLaYmJgWrBgAALQ0v/n5BZvNplWrViktLa1Bxw0cOFCXXXaZXnnllVr3V1ZWqrKy0vO4tLRUMTEx/PwCAAABpFX9/EJiYqLee++9OveHhoYqNDS0BSsCAAC+FFDTUrXJz8+X08kv7QIAgNN8eubmxIkT+vTTTz2Pi4qKlJ+fr8jISF122WWaOXOmvvrqK/3v//6vJOnPf/6zYmNjdfXVV6uiokJLlixRTk6ONm7c6Ku3AAAA/IxPw83u3bs1ePBgz+Pp06dLkiZMmKCsrCwVFxfr0KFDnv2nTp3Sf/3Xf+mrr77S+eefrx49eujdd9/1eg4AANC6+c0FxS2lIRckAQAA/9CQ7++Av+YGAADgpwg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUtr4ugDgbKrcRrlFx3WsrEJR4XYlxkYqOMjm67IAAH6KcAO/ll1QrDlrC1XsqvC0OR12ZaTGa0SC04eVAQD8FdNS8FvZBcVKX5rnFWwkqcRVofSlecouKPZRZQAAf0a4gV+qchvNWVsoU8u+6rY5awtV5a6tBwCgNSPcwC/lFh2vccbmp4ykYleFcouOt1xRAICAQLiBXzpWVnewaUw/AEDrQbiBX4oKtzdpPwBA60G4gV9KjI2U02FXXTd823T6rqnE2MiWLAsAEAAIN/BLwUE2ZaTGS1KNgFP9OCM1nvVuAAA1EG7gt0YkOLVoXB9FO7ynnqIddi0a14d1bgAAtWIRP/i1EQlODYuPZoViAEC9EW7g94KDbErqcpGvywAABAimpQAAgKUQbgAAgKUQbgAAgKUQbgAAgKX4NNxs375dqamp6tChg2w2m1avXn3WY7Zu3ao+ffooNDRUXbt2VVZWVrPXCQAAAodPw015ebl69uyphQsX1qt/UVGRRo0apcGDBys/P1/Tpk3TPffcow0bNjRzpQAAIFD49FbwkSNHauTIkfXuv3jxYsXGxuqpp56SJF111VV67733tGDBAqWkpDRXmQAAIIAE1DU3u3bt0tChQ73aUlJStGvXrjqPqaysVGlpqdcGAACsK6DCTUlJidq3b+/V1r59e5WWlurkyZO1HpOZmSmHw+HZYmJiWqJUAADgIwEVbhpj5syZcrlcnu3w4cO+LgkAADSjgPr5hejoaB09etSr7ejRo4qIiFBYWFitx4SGhio0NLQlygMAAH4goM7cJCUlafPmzV5tmzZtUlJSko8qAgAA/san4ebEiRPKz89Xfn6+pNO3eufn5+vQoUOSTk8pjR8/3tP/3nvv1eeff66HHnpIH3/8sZ599lmtWLFCDzzwgC/KBwAAfsin4Wb37t3q3bu3evfuLUmaPn26evfurVmzZkmSiouLPUFHkmJjY/X2229r06ZN6tmzp5566iktWbKE28ABAICHzRhjfF1ESyotLZXD4ZDL5VJERISvywEAAPXQkO/vgLrmBgAA4GwINwAAwFIINwAAwFICap0boLGq3Ea5Rcd1rKxCUeF2JcZGKjjI5uuyAADNgHADy8suKNactYUqdlV42pwOuzJS4zUiwenDygAAzYFpKVhadkGx0pfmeQUbSSpxVSh9aZ6yC4p9VBkAoLkQbmBZVW6jOWsLVdtaB9Vtc9YWqsrdqlZDAADLI9zAsnKLjtc4Y/NTRlKxq0K5RcdbrigAQLMj3MCyjpXVHWwa0w8AEBgIN7CsqHB7k/YDAAQGwg0sKzE2Uk6HXXXd8G3T6bumEmMjW7IsAEAzI9zAsoKDbMpIjZekGgGn+nFGajzr3QCAxRBuYGkjEpxaNK6Poh3eU0/RDrsWjevDOjcAYEEs4gfLG5Hg1LD4aFYoBoBWgnCDViE4yKakLhf5ugwAQAtgWgoAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFhKG18XYBVVbqPcouM6VlahqHC7EmMjFRxk83VZAAC0OoSbJpBdUKw5awtV7KrwtDkddmWkxmtEgtOHlQEA0PowLXWOsguKlb40zyvYSFKJq0LpS/OUXVDso8oAAGidCDfnoMptNGdtoUwt+6rb5qwtVJW7th4AAKA5EG7OQW7R8RpnbH7KSCp2VSi36HjLFQUAQCtHuDkHx8rqDjaN6QcAAM4d4eYcRIXbm7QfAAA4d4Sbc5AYGymnw666bvi26fRdU4mxkS1ZFgAArRrh5hwEB9mUkRovSTUCTvXjjNR41rsBAKAFEW7O0YgEpxaN66Noh/fUU7TDrkXj+rDODQAALYxF/JrAiASnhsVHs0IxAAB+gHDTRIKDbErqcpGvywAAoNVjWgoAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFhKq1uh2BgjSSotLfVxJQAAoL6qv7erv8fPpNWFm7KyMklSTEyMjysBAAANVVZWJofDccY+NlOfCGQhbrdbR44cUXh4uGy2pv1hy9LSUsXExOjw4cOKiIho0udu7Rjb5sG4Nh/Gtvkwts3D38fVGKOysjJ16NBBQUFnvqqm1Z25CQoKUseOHZv1NSIiIvzyg2EFjG3zYFybD2PbfBjb5uHP43q2MzbVuKAYAABYCuEGAABYCuGmCYWGhiojI0OhoaG+LsVyGNvmwbg2H8a2+TC2zcNK49rqLigGAADWxpkbAABgKYQbAABgKYQbAABgKYQbAABgKYSbBlq4cKE6d+4su92ua6+9Vrm5uXX2zcrKks1m89rsdnsLVhsYtm/frtTUVHXo0EE2m02rV68+6zFbt25Vnz59FBoaqq5duyorK6vZ6wxEDR3brVu31vjM2mw2lZSUtEzBASIzM1P9+vVTeHi4oqKilJaWpgMHDpz1uJUrV6pbt26y2+3q3r273nnnnRaoNrA0Zmz5W1s/ixYtUo8ePTyL9CUlJWn9+vVnPCZQP7OEmwZYvny5pk+froyMDOXl5alnz55KSUnRsWPH6jwmIiJCxcXFnu3gwYMtWHFgKC8vV8+ePbVw4cJ69S8qKtKoUaM0ePBg5efna9q0abrnnnu0YcOGZq408DR0bKsdOHDA63MbFRXVTBUGpm3btmny5Ml6//33tWnTJv34448aPny4ysvL6zxm586dGjt2rO6++27t3btXaWlpSktLU0FBQQtW7v8aM7YSf2vro2PHjnrssce0Z88e7d69W0OGDNEtt9yi/fv319o/oD+zBvWWmJhoJk+e7HlcVVVlOnToYDIzM2vt/9JLLxmHw9FC1VmDJLNq1aoz9nnooYfM1Vdf7dU2ZswYk5KS0oyVBb76jO2WLVuMJPPdd9+1SE1WcezYMSPJbNu2rc4+t912mxk1apRX27XXXmsmTZrU3OUFtPqMLX9rG+/CCy80S5YsqXVfIH9mOXNTT6dOndKePXs0dOhQT1tQUJCGDh2qXbt21XnciRMn1KlTJ8XExJwxIaP+du3a5fXvIEkpKSln/HdAw/Tq1UtOp1PDhg3Tjh07fF2O33O5XJKkyMjIOvvwuW2c+oytxN/ahqqqqtKyZctUXl6upKSkWvsE8meWcFNP33zzjaqqqtS+fXuv9vbt29d5PUJcXJxefPFFrVmzRkuXLpXb7VZycrK+/PLLlijZskpKSmr9dygtLdXJkyd9VJU1OJ1OLV68WG+88YbeeOMNxcTEaNCgQcrLy/N1aX7L7XZr2rRp6t+/vxISEursV9fnluuZ6lbfseVvbf3t27dPbdu2VWhoqO69916tWrVK8fHxtfYN5M9sq/tV8JaUlJTklYiTk5N11VVX6bnnntO8efN8WBlQu7i4OMXFxXkeJycn67PPPtOCBQv0yiuv+LAy/zV58mQVFBTovffe83UpllPfseVvbf3FxcUpPz9fLpdLr7/+uiZMmKBt27bVGXACFWdu6uniiy9WcHCwjh496tV+9OhRRUdH1+s5zjvvPPXu3Vuffvppc5TYakRHR9f67xAREaGwsDAfVWVdiYmJfGbrMGXKFK1bt05btmxRx44dz9i3rs9tff9+tDYNGduf429t3UJCQtS1a1f17dtXmZmZ6tmzp/7yl7/U2jeQP7OEm3oKCQlR3759tXnzZk+b2+3W5s2b65yv/Lmqqirt27dPTqezucpsFZKSkrz+HSRp06ZN9f53QMPk5+fzmf0ZY4ymTJmiVatWKScnR7GxsWc9hs9t/TRmbH+Ov7X153a7VVlZWeu+gP7M+vqK5kCybNkyExoaarKyskxhYaH53e9+Z9q1a2dKSkqMMcbceeedZsaMGZ7+c+bMMRs2bDCfffaZ2bNnj7n99tuN3W43+/fv99Vb8EtlZWVm7969Zu/evUaS+dOf/mT27t1rDh48aIwxZsaMGebOO+/09P/888/N+eefbx588EHz0UcfmYULF5rg4GCTnZ3tq7fgtxo6tgsWLDCrV682n3zyidm3b5+5//77TVBQkHn33Xd99Rb8Unp6unE4HGbr1q2muLjYs/3www+ePj//e7Bjxw7Tpk0b8+STT5qPPvrIZGRkmPPOO8/s27fPF2/BbzVmbPlbWz8zZsww27ZtM0VFRebDDz80M2bMMDabzWzcuNEYY63PLOGmgZ555hlz2WWXmZCQEJOYmGjef/99z76BAweaCRMmeB5PmzbN07d9+/bmpptuMnl5eT6o2r9V33788616LCdMmGAGDhxY45hevXqZkJAQc/nll5uXXnqpxesOBA0d28cff9x06dLF2O12ExkZaQYNGmRycnJ8U7wfq21MJXl9Dn/+98AYY1asWGGuvPJKExISYq6++mrz9ttvt2zhAaAxY8vf2vq56667TKdOnUxISIi55JJLzI033ugJNsZY6zNrM8aYljtPBAAA0Ly45gYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QZAQKmqqlJycrJGjx7t1e5yuRQTE6NHHnlEknTfffepb9++Cg0NVa9evXxQKQBfIdwACCjBwcHKyspSdna2/va3v3nap06dqsjISGVkZHja7rrrLo0ZM8YXZQLwoTa+LgAAGurKK6/UY489pqlTp2rIkCHKzc3VsmXL9MEHHygkJESS9PTTT0uSvv76a3344Ye+LBdACyPcAAhIU6dO1apVq3TnnXdq3759mjVrlnr27OnrsgD4AcINgIBks9m0aNEiXXXVVerevbtmzJjh65IA+AmuuQEQsF588UWdf/75Kioq0pdffunrcgD4CcINgIC0c+dOLViwQOvWrVNiYqLuvvtuGWN8XRYAP0C4ARBwfvjhB/3mN79Renq6Bg8erP/5n/9Rbm6uFi9e7OvSAPgBwg2AgDNz5kwZY/TYY49Jkjp37qwnn3xSDz30kL744gtJ0qeffqr8/HyVlJTo5MmTys/PV35+vk6dOuXDygG0BJvhPC6AALJt2zbdeOON2rp1q66//nqvfSkpKfr3v/+td999V4MHD9a2bdtqHF9UVKTOnTu3ULUAfIFwAwAALIVpKQAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCn/DxS0EEguDk2aAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the data\n",
    "plt.scatter(df['X1'], df['X2'])\n",
    "plt.title('Scatter Plot of X1 vs X2')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatter plot seems to suggest that the diagonal would be a better primary axis as it captures the most important variance of the data records. Since not all the data records are on the diagonal but instead scattered around it, we can expect that the second highest variability of these data records will be orthogonal to the diagonal axis. We can say that the first principal component is expected to be the diagonal and the second principal component is expected to be the axis orthogonal to the diagonal.\n",
    "\n",
    "We could reduce the variables by using only the new diagonal axis and throwing away the axis orthogonal to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7852105167122736\n",
      "    X1   X2    X1_std    X2_std\n",
      "0  2.5  2.4  0.878745  0.578857\n",
      "1  0.5  0.7 -1.668342 -1.429422\n",
      "2  2.2  2.9  0.496682  1.169527\n",
      "3  1.9  2.2  0.114619  0.342589\n",
      "4  3.1  3.0  1.642872  1.287661\n",
      "5  2.3  2.7  0.624036  0.933259\n",
      "6  2.0  1.6  0.241973 -0.366216\n",
      "7  1.0  1.1 -1.031570 -0.956886\n",
      "8  1.5  1.6 -0.394799 -0.366216\n",
      "9  1.1  0.9 -0.904216 -1.193154\n"
     ]
    }
   ],
   "source": [
    "mean_X1 = df['X1'].mean()\n",
    "mean_X2 = df['X2'].mean()\n",
    "std_X1 = df['X1'].std()\n",
    "std_X2 = df['X2'].std()\n",
    "print(std_X1)\n",
    "\n",
    "df['X1_std'] = (df['X1'] - mean_X1) / std_X1\n",
    "df['X2_std'] = (df['X2'] - mean_X2) / std_X2\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Calculate the Covariance Matrix\n",
    "The equation to calculate the covariance is given as follows:\n",
    "\n",
    "$$c_{ij} = \\frac{1}{N-1}\\sum_{k = 1}^{N}(x_{i} - \\bar{x_{i}})_{k}(x_{j} - \\bar{x_{j}})_{k}$$\n",
    "\n",
    "So, for example\n",
    "\n",
    "$$c_{11} = \\frac{1}{N-1}\\sum_{k = 1}^{N}(x_{1} - \\bar{x_{1}})_{k}^{2}$$\n",
    "\n",
    "and\n",
    "\n",
    "$$c_{12} = \\frac{1}{N-1}\\sum_{k = 1}^{N}(x_{1} - \\bar{x_{1}})_{k}(x_{2} - \\bar{x_{2}})_{k}$$\n",
    "\n",
    "We can calculate this in python as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          X1        X2\n",
      "X1  0.616556  0.615444\n",
      "X2  0.615444  0.716556\n"
     ]
    }
   ],
   "source": [
    "cov_matrix = df[['X1', 'X2']].cov()\n",
    "print(cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Calculate the eigenvalues and eigenvectors\n",
    "Let the covariance matrix be called $C$. We want to transform this matrix so that it is a matrix in its own eigenspace. In other words, we want to find the eigenvalues and eigenvectors of this matrix in order to represent the covariance in an eigenspace, giving us orthogonal components that only vary along their components, allowing for dimensionality reduction. Any matrix that has the following property:\n",
    "\n",
    "$$ C\\vec{x} = \\lambda \\vec{x} $$\n",
    "\n",
    "essentially transforms the vector $\\vec{x}$ along its own component; i.e., the transformation simply scales the vector. We therefore need to solve this equation to find the vectors $\\vec{x}$ such that\n",
    "\n",
    "$$ (C - \\lambda \\cdot I) \\vec{x} = \\vec{0} $$\n",
    "\n",
    "where $\\vec{x}$ is not just the trivial solution \\vec{x} = \\vec{0}. This is only satisfied if the matrix $(C - \\lambda \\cdot I)$ is composed of linearly dependent columns/rows, namely:\n",
    "\n",
    "$$ det(C - \\lambda \\cdot I) = 0 $$\n",
    "\n",
    "which would give us a characteristic polynomial in $\\lambda$. It is these values of $\\lambda$ which provide the eigenvalues, which can then be plugged back into the first equation above and solved to yield the eigenvectors. In fact, the matrix $S$ formed by the eigenvectors is related to the eigenvalues through diagonalization of the matrix $C$ as follows: $D = S^{-1}CS$ where $D$ is the diagonal matrix of eigenvalues. This shows that the eigenvalues provide a new basis for the covariance data where the eigenvector matrix is a change of basis matrix. In other words, to get the data into a new form, we use the change of basis matrix $S$ to transform to the new eigenbasis, perform the covariance transformation $C$, then return back to the original basis with $S^{-1}$.\n",
    "\n",
    "$$C - \\lambda \\cdot I = \\begin{pmatrix}0.616556-\\lambda, 0.615444 \\\\ 0.615444, 0.716556 - \\lambda \\end{pmatrix}$$\n",
    "\n",
    "which leads to the characteristic polynomial:\n",
    "\n",
    "$$\\lambda^{2} - 1.333\\lambda + 0.063 = 0$$\n",
    "\n",
    "These can be calculated in python with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues: [0.0490834  1.28402771]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix);\n",
    "print(\"Eigenvalues:\", eigenvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These eigenvalues represent the variance explained by each principal component, i.e, the diagonal and its orthogonal line in the example above. The larger the eigenvalue, the more variance that component explains in the data.\n",
    "\n",
    "The eigenvectors (or principal components) are calculated for each eigenvalue in turn. Starting with the largest:\n",
    "\n",
    "$$(C - \\lambda_{1} \\cdot I)\\vec{x_{PC1}} = \\vec{0} $$\n",
    "$$ \\begin{pmatrix} -0.6675, 0.6154 \\\\ 0.6154, -0.5675 \\end{pmatrix} \\begin{pmatrix} x_{PC1_1} \\\\ x_{PC1_2} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$$\n",
    "\n",
    "This leads to $x_{PC1_1} = 1$ and $x_{PC1_2} = 1.084$. Next, normalize these by taking the square root of the sum of squares of both values and using that result to divide the vector, creating a unit vector. We get the following results, as calculated by Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvectors: [[-0.73517866 -0.6778734 ]\n",
      " [ 0.6778734  -0.73517866]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Eigenvectors:\", eigenvectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two eigenvectors are orthogonal (i.e., they are at right-angles on the chart above), which can be demonstrated by taking the dot product of the two eigenvecots and showing that they are equal to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dot product of the eigenvectors is:  -1.8337180666905926e-17\n"
     ]
    }
   ],
   "source": [
    "eigenvector_1 = eigenvectors[:, 0]\n",
    "eigenvector_2 = eigenvectors[:, 1]\n",
    "dot_product = np.dot(eigenvector_1, eigenvector_2)\n",
    "print(\"The dot product of the eigenvectors is: \", dot_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is practically zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Formulate the principle components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first principle component is the eigenvector that corresponds to the eigenvalue with the highest value. We can determine the order of PCs according to their eigenvalues from highest to lowest. This can be done with the following equation that calculates the percentage of variance each principal component represents:\n",
    "\n",
    "$$ H_{PC_{i}} = \\frac{\\lambda_{i}}{\\lambda_{1} + ... + \\lambda_{M}} \\cdot 100% $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of variance for each principal component: \n",
      "Principal Component 1: 3.68%\n",
      "Principal Component 2: 96.32%\n"
     ]
    }
   ],
   "source": [
    "total_variance = np.sum(eigenvalues)\n",
    "variance_percentages = (eigenvalues / total_variance) * 100\n",
    "print(\"Percentage of variance for each principal component: \")\n",
    "for i, variance in enumerate(variance_percentages):\n",
    "    print(f\"Principal Component {i+1}: {variance:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Dimensionality Reduction\n",
    "We can decide to ignore the principal components with less significance, i.e., those that have a lower percentage of the variance. This reduces our dataset to a smaller set of principal components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Transforming the original dataset\n",
    "The technique to do this is to create the transformation matrix from the eigenvectors and transform the convariance matrix through matrix multiplication. It is important to note that the transformed data show the same relation. The only difference is the transformation so that the axes are the principal components and not the variables X1 and X2. - Though not sure about this. I can see the data in the textbook shows that the variance of the new matrix is wider for the first component and narrower for the second component, but it doesn't seem useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.8704719  -0.93819557]\n",
      " [-0.03451501 -0.10960293]]\n"
     ]
    }
   ],
   "source": [
    "cov_transformed = np.dot(eigenvectors, cov_matrix)\n",
    "print(cov_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
