{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks\n",
    "\n",
    "Previously, we looked at the case where $h_{\\theta}(x) = \\theta^{T}x$, possible in linear and logistic regression. This model is linear in $\\theta$. ANNs are models that are non-linear in both the parameters $\\theta$ and the inputs $x$.\n",
    "\n",
    "Suppose $\\{(x^{(i)}, y^{(i)})\\}_{i=1}^{n}$ are the training examples and $y^{(i)} \\in \\mathbb{R}$ and $h_{\\theta}(x) \\in \\mathbb{R}$.\n",
    "\n",
    "If we define the least squares cost function for the $i$-th example as $J^{(i)}(\\theta) = \\frac{1}{2}(h_{\\theta}(x^{(i)}) - y^{(i)})^{2}$, then we can also define the mean-square cost function for the dataset as:\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{n} \\sum_{i=1}^{n}J^{(i)}(\\theta) $$\n",
    "\n",
    "which looks just the same as for linear regression except there is now a constant $\\frac{1}{n}$ in front."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient descent\n",
    "\n",
    "Gradient descent is an iterative technique for finding the minimum of a function. For an analytical function, the minimum can be found simply by setting the first derivative to zero and solving for the parameters. An alternative is to imagine our cost function as a curve in space, and placing a ball at a random point. If we let go of the ball, it will fall down the gradient of steepest descent, namely in the direction opposite to $\\nabla_{\\theta}J(\\theta)$.\n",
    "\n",
    "Let's image that, given a function $f(x,y)$ we start at a particular point $(x_{0}, y_{0})$. Then we can move a small amount in the direction of steepest ascent to find a new point $(x_{1}, y_{1})$, i.e., $\\vec{x_{1}} = \\vec{x_{0}} - \\alpha\\nabla{f(\\vec{x_{0}})}$, where $\\alpha$ controls the amount by which we move down the curve, and is known as the **learning rate**. We can repeat this process using $(x_{1}, y_{1})$ as our input and calculating $(x_{2}, y_{2})$. Eventually, by repeating this process many times, we will converge on the minimum point. We can summarize this process in the following equation:\n",
    "\n",
    "$$ \\theta \\coloneqq  \\theta - \\alpha\\nabla_{\\theta}J(\\theta) $$\n",
    "\n",
    "**A simple example for demonstration**: Let $f(x,y) = 4x^{2} + y^{2}$. We know that $\\nabla{f(x,y)} = (8x, 2y)$, and if we set this zero and solve for $x$ and $y$ we find the minimum point is $(0,0)$. However, instead of this approach, let's choose a position on the function, $(x, y) = (1, 1)$ and run gradient descent. Let's set the learning rate to be 0.1 and see how many iterations it takes to reach the minimum point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999996 0.8\n",
      "0.03999999999999998 0.64\n",
      "0.007999999999999993 0.512\n",
      "0.0015999999999999981 0.4096\n",
      "0.00031999999999999954 0.32768\n",
      "6.399999999999988e-05 0.26214400000000004\n",
      "1.2799999999999972e-05 0.20971520000000005\n",
      "2.559999999999994e-06 0.16777216000000003\n",
      "5.119999999999987e-07 0.13421772800000004\n",
      "1.023999999999997e-07 0.10737418240000003\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.1 # learning rate\n",
    "(x, y) = (1, 1) # starting points of the function\n",
    "n_iter = 10 # number of iterations\n",
    "\n",
    "for i in range(n_iter):\n",
    "    partial_x = 8*x\n",
    "    partial_y = 2*y\n",
    "    x = x - alpha*partial_x\n",
    "    y = y - alpha*partial_y\n",
    "    print(x, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, as we see from the above, we get close and close to the minimum point, although the y-coordinate appears to be taking much longer than the x-coordinate. Playing with the learning rate will reveal a few interesting features:\n",
    "- too high (0.5) and the x-coordinate will jump around all over the place\n",
    "- too low (0.01) and convergence will take a very long time, requiring many more iterations.\n",
    "\n",
    "**Using real data**\n",
    "The above example uses a function that we are already provided with. However, when we are using training data, we don't know the value of $\\nabla_{\\theta}J(\\theta)$. In fact, we are trying to find $\\theta$ such that this value is zero, and this is why gradient descent is useful.\n",
    "\n",
    "When studying linear regression, we used matrix algebra to find the normal equation. The normal equation is an analytical solution to the case that $\\nabla_{\\theta}J(\\theta) = 0$. In fact, just before setting this value to zero, we have:\n",
    "\n",
    "$$\\vec\\nabla_{\\theta}J(\\theta) =  X^{T}X\\theta - X^{T}\\vec{y} $$\n",
    "\n",
    "This is the same as calculating the error = prediction - observation, then multiplying the transpose of the data with the error.\n",
    "\n",
    "This means we can use the data in the gradient descent algorithm. Depending on the cost function we use, this formula can change, but essentially the process is like this. We can look at example of gradient descent. Let's repeat the linear regression of sales ~ advertising to see that gradient descent can help us to find the coefficients. The following uses a BATCH gradient descent, so the $(1/n)$ term becomes important since the cost function is essentially the Mean Square Error (MSE), which is the Residual Square Error (RSE) divided by the number of data points (below, labelled m).\n",
    "\n",
    "After some tweaking, a learning rate of 0.001 and 10000 iterations led to an approximation of the coefficients which is close to that given by the normal equations by linear regression in chapter 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.047534382832213604 7.0329255123942325\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Compute the cost function to monitor its decrease during gradient descent\n",
    "def compute_cost(X, y, coefs):\n",
    "    m = len(y)\n",
    "    prediction = X @ coefs\n",
    "    cost = (1 / (2 * m)) * np.sum((prediction - y) ** 2)\n",
    "    return cost\n",
    "\n",
    "# Prepare a function for gradient descent\n",
    "def gradient_descent(n_iter, X, y, coefs, alpha):\n",
    "    m = len(y) # The number of data points\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        # # Randomly sample an index j\n",
    "        # j = np.random.randint(0, m)\n",
    "\n",
    "        # # Compute the gradient using the j-th data point - this is stochastic gradient descent\n",
    "        # X_j = X[j, :].reshape(1, -1) # Shape (1, n_features)\n",
    "        # y_j = y[j] # Shape (1,)\n",
    "        # gradient = X_j.T @ (X_j @ coefs - y_j) # Shape (n_features, 1)\n",
    "        # coefs = coefs - alpha * gradient\n",
    "\n",
    "        # Compute the prediction\n",
    "        predictions = X @ coefs # Shape (m,)\n",
    "        \n",
    "        # Compute the gradient using all data points\n",
    "        errors = predictions - y #Shape (m,)\n",
    "        gradient = (1/m) * (X.T @ errors) # Shape (n_features, )\n",
    "\n",
    "        # Update coefficients\n",
    "        coefs = coefs - alpha * gradient\n",
    "\n",
    "        cf = compute_cost(X, y, coefs)\n",
    "        # print(f\"Iteration {i + 1}: Cost = {cf}, Coefs = {coefs}\")\n",
    "    return coefs\n",
    "\n",
    "\n",
    "\n",
    "# Load the data in\n",
    "df = pd.read_csv(\"Data/Advertising.csv\")\n",
    "\n",
    "# Keep the mean and standard deviations of the data for conversion back to original scale later\n",
    "meanX = df['TV'].mean()\n",
    "meanY = df['sales'].mean()\n",
    "stdX = df['TV'].std()\n",
    "stdY = df['sales'].std()\n",
    "\n",
    "# Normalize / Standardize the data\n",
    "df[['TV', 'sales']] = (df[['TV', 'sales']] - df[['TV', 'sales']].mean()) / df[['TV', 'sales']].std()\n",
    "\n",
    "# Prepare the data\n",
    "X = np.c_[np.ones(df.shape[0]), df['TV'].values] # Add intercept terms\n",
    "y = df['sales'].values\n",
    "\n",
    "# Initialize coefficients as a numpy array\n",
    "coefs = np.array([0, 0])\n",
    "\n",
    "# Now run the calculation\n",
    "new_coefs = gradient_descent(10000, X, y, coefs, 0.001);\n",
    "\n",
    "# Convert the coefficients back to their original scale.\n",
    "beta1 = new_coefs[1] * stdY / stdX\n",
    "beta0 = meanY - (beta1*meanX);\n",
    "print(beta1, beta0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a neural network?\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
